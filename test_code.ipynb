{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37526e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41bbf80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(32, 24), nn.ReLU(), nn.Linear(24, 16), nn.ReLU())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62ffeccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 30, 16])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(8, 30, 32)\n",
    "y = model(x)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f885521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <class 'torch.nn.modules.container.Sequential'> True\n",
      "0 <class 'torch.nn.modules.linear.Linear'> True\n",
      "1 <class 'torch.nn.modules.activation.ReLU'> True\n",
      "2 <class 'torch.nn.modules.linear.Linear'> True\n",
      "3 <class 'torch.nn.modules.activation.ReLU'> True\n"
     ]
    }
   ],
   "source": [
    "# iterating through all of the modules\n",
    "for name, module in model.named_modules():\n",
    "    print(name, type(module), isinstance(module, nn.Module))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd0e54dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=32, out_features=24, bias=True)\n"
     ]
    }
   ],
   "source": [
    "layer = model[0]\n",
    "print(layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7875fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_fn(module: nn.Module, args, output):\n",
    "    print(f\"Hello! we are inside of a forward hook. My module is {module}, the inputs are {args}, the outputs are {output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bbcbc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = layer.register_forward_hook(hook_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8596318b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! we are inside of a forward hook. My module is Linear(in_features=32, out_features=24, bias=True), the inputs are (tensor([[ 0.4668,  1.5062, -1.6923,  1.3530, -0.7549,  1.6089,  1.5451,  0.5262,\n",
      "         -0.6871,  0.3373, -0.8215, -0.3513, -1.1234, -1.4878, -0.3461, -1.4130,\n",
      "          0.6693,  0.0783, -1.1228, -0.2543,  0.6861,  0.5037, -0.6093, -0.2720,\n",
      "         -0.3580, -0.5863,  1.1232, -1.8202, -0.0596,  0.8736, -1.1066,  1.7741]]),), the outputs are tensor([[ 0.5048,  0.3148, -0.9752, -0.5608,  0.4318, -0.4555, -0.5908, -0.0170,\n",
      "          1.1975, -0.4305,  0.1371, -0.0959, -0.5939,  0.8271,  1.8683, -0.4340,\n",
      "          0.7912,  0.3859,  0.3985, -0.9812, -0.2133, -0.2314, -0.4976, -0.4333]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0859, 0.0000, 0.0000, 0.0000, 0.3881, 0.6115, 0.4115, 0.0000, 0.0000,\n",
       "         0.0000, 0.0220, 0.0000, 0.0000, 0.5266, 0.0000, 0.1157]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(1, 32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9ff1dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "handle.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "473c37cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0580, 0.5276, 0.0815, 0.0000, 0.1239,\n",
       "         0.0000, 0.1051, 0.3343, 0.0000, 0.1487, 0.0000, 0.0045]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(1, 32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be0167e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting it all together:\n",
    "# let's iterate through each module and add a forward hook that just prints the layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "247689f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_fn_print_layer(module: nn.Module, args, output):\n",
    "    print(module)\n",
    "\n",
    "def prehook_fn_print_layer(module: nn.Module, args):\n",
    "    print(\"prehook\", module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48e46c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "handles = {}\n",
    "for name, module in model.named_modules():\n",
    "    # handles[name] = module.register_forward_hook(hook_fn_print_layer)\n",
    "    handles[name] = module.register_forward_pre_hook(prehook_fn_print_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58bdc4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prehook Sequential(\n",
      "  (0): Linear(in_features=32, out_features=24, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=24, out_features=16, bias=True)\n",
      "  (3): ReLU()\n",
      ")\n",
      "prehook Linear(in_features=32, out_features=24, bias=True)\n",
      "prehook ReLU()\n",
      "prehook Linear(in_features=24, out_features=16, bias=True)\n",
      "prehook ReLU()\n"
     ]
    }
   ],
   "source": [
    "model(torch.randn(1, 32));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c6ed3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for handle in handles.values():\n",
    "    handle.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d59f71e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini prototype of OBS\n",
    "# our overall goal is to build a container that collects matrix weights, input vectors, and output vectors for each\n",
    "# nn.Linear in the graph\n",
    "\n",
    "# OBS will iterate through these in order and prune the layers one-by-one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "211dea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class OBSLinearCache:\n",
    "    name: str = None\n",
    "    weight: Tensor = None\n",
    "    input: Tensor = None\n",
    "    output: Tensor = None\n",
    "    module: nn.Linear = None\n",
    "\n",
    "def get_layer_hook(name: str):\n",
    "    cache = OBSLinearCache()\n",
    "    def hook_fn(module, args, outputs):\n",
    "        cache.module = module\n",
    "        cache.name = name\n",
    "        cache.input = args\n",
    "        cache.output = outputs\n",
    "        cache.weight = module.weight\n",
    "\n",
    "    return hook_fn, cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cb56110",
   "metadata": {},
   "outputs": [],
   "source": [
    "caches = {}\n",
    "hooks = {}\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if not isinstance(module, nn.Linear):\n",
    "        continue\n",
    "\n",
    "    hook_fn, cache = get_layer_hook(name)\n",
    "    caches[name] = cache\n",
    "    hooks[name] = module.register_forward_hook(hook_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e67f432c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': OBSLinearCache(name=None, weight=None, input=None, output=None, module=None),\n",
       " '2': OBSLinearCache(name=None, weight=None, input=None, output=None, module=None)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2896cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(torch.randn(8, 32))\n",
    "for handle in handles.values():\n",
    "    handle.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c227603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': OBSLinearCache(name='0', weight=Parameter containing:\n",
       " tensor([[-3.0700e-02,  1.7464e-02, -1.4900e-01,  1.0195e-01, -1.0894e-01,\n",
       "           1.3645e-01, -9.9031e-02,  1.3497e-01, -5.0742e-02,  6.2458e-02,\n",
       "          -1.7630e-01,  4.7019e-02,  5.9899e-02, -1.0123e-01, -1.2802e-01,\n",
       "           6.1456e-02,  1.3629e-01,  6.3063e-02,  1.4376e-01, -3.8462e-02,\n",
       "           1.7458e-01, -1.7630e-01,  8.1967e-02,  1.3386e-01,  1.7037e-01,\n",
       "           9.4823e-02,  5.2966e-04,  6.5677e-02, -8.5024e-02,  8.4206e-02,\n",
       "           6.0984e-02,  3.6805e-02],\n",
       "         [ 6.2203e-02, -1.7380e-01, -6.5445e-02,  2.0842e-02, -1.2105e-01,\n",
       "          -5.1732e-02, -6.5871e-02, -2.2648e-02,  1.5204e-02,  1.3887e-02,\n",
       "           1.3138e-01, -1.4400e-01,  1.1331e-01,  1.5506e-01,  8.1966e-02,\n",
       "          -1.7560e-01, -6.4073e-02, -4.2885e-02,  1.0424e-02,  2.8951e-02,\n",
       "           6.7926e-02, -7.9798e-02,  3.8113e-02,  5.8120e-03, -6.4037e-02,\n",
       "          -4.8705e-02,  1.7367e-01, -1.2617e-01, -1.2156e-02,  8.7100e-02,\n",
       "          -7.9247e-02,  1.4837e-01],\n",
       "         [-6.5671e-02, -1.4818e-01, -1.3070e-01,  1.0380e-01,  1.3772e-01,\n",
       "          -1.2826e-01, -8.9594e-02, -1.4196e-01,  1.0479e-01, -1.4588e-01,\n",
       "           1.2958e-01, -1.5651e-02,  1.6259e-01, -8.3621e-02,  4.8650e-04,\n",
       "          -8.6623e-02,  2.4424e-02, -1.0438e-01,  1.1287e-01,  9.5538e-02,\n",
       "          -1.6952e-01,  1.6915e-01,  1.0932e-01, -6.3744e-02, -3.6224e-02,\n",
       "           8.7757e-02,  1.0123e-01,  5.0811e-02, -1.3346e-01,  2.2247e-02,\n",
       "          -6.9110e-02, -1.2898e-01],\n",
       "         [ 3.0497e-02, -6.7274e-02,  1.2865e-03, -9.4496e-02,  5.8419e-02,\n",
       "          -8.0671e-02, -3.8758e-02, -1.3696e-01, -1.0307e-01,  1.6693e-01,\n",
       "          -1.9710e-02,  1.2993e-01,  1.7263e-01,  8.2594e-02,  1.5846e-01,\n",
       "           6.0877e-02,  3.8465e-02, -8.1335e-02,  9.6509e-02, -1.4784e-01,\n",
       "           1.1365e-01,  1.5989e-02, -4.7460e-02, -1.3041e-01, -1.1150e-01,\n",
       "          -6.2745e-02, -1.4820e-01, -1.1204e-01,  1.4194e-01,  3.1910e-02,\n",
       "          -1.1247e-01,  3.5444e-02],\n",
       "         [-2.2401e-02,  4.8570e-02,  2.1321e-02,  1.4451e-02, -7.7217e-02,\n",
       "          -2.6017e-03, -1.7381e-01, -2.4474e-02, -9.7737e-02, -1.5389e-01,\n",
       "          -8.4464e-02,  4.9513e-02, -1.1015e-01, -8.0636e-02, -2.8805e-02,\n",
       "          -1.1730e-01,  1.4791e-01,  2.8593e-02, -1.4254e-01,  4.4331e-02,\n",
       "          -6.7401e-02,  3.1152e-02, -1.6828e-01,  5.0706e-02, -1.7555e-01,\n",
       "           8.8623e-02,  1.6536e-01,  1.7667e-01, -1.3848e-01,  6.3655e-02,\n",
       "           5.0679e-02, -9.0354e-02],\n",
       "         [ 7.6020e-03, -1.1869e-01, -1.2917e-01,  1.1378e-01,  8.6520e-02,\n",
       "          -1.3960e-02, -5.3306e-02,  1.1654e-01,  2.5779e-03,  4.6129e-02,\n",
       "          -1.0399e-02,  1.3374e-01, -7.2957e-02,  1.2380e-01, -5.8043e-02,\n",
       "           1.1242e-01, -1.2338e-02, -4.3520e-02,  7.7133e-02,  6.5724e-02,\n",
       "          -1.7322e-01,  1.6074e-01,  1.6279e-01,  5.1984e-02, -4.0273e-02,\n",
       "          -1.5654e-01, -3.9013e-02,  1.3620e-01,  7.4736e-02,  1.3505e-01,\n",
       "           1.3341e-01,  1.1753e-01],\n",
       "         [ 5.2765e-02,  8.4040e-02,  4.2931e-03,  5.1388e-02,  5.3408e-02,\n",
       "          -1.6743e-01,  6.5076e-03, -2.9906e-02,  1.7059e-01,  1.0554e-01,\n",
       "          -1.2154e-01,  1.4113e-01,  1.3876e-01,  1.0757e-01,  5.6615e-02,\n",
       "          -9.0138e-02, -1.2033e-01,  1.7376e-02,  1.5350e-01, -6.6957e-02,\n",
       "          -1.5802e-01, -5.5786e-02, -5.4269e-02, -1.4455e-02,  3.3077e-02,\n",
       "          -1.1208e-01,  6.1829e-02,  1.4319e-01,  6.2857e-02,  1.2141e-01,\n",
       "          -1.4777e-01, -9.8743e-02],\n",
       "         [-1.5561e-01, -7.0893e-02,  7.7407e-02,  1.5220e-01, -9.6801e-02,\n",
       "          -1.3653e-01, -2.1629e-02,  7.2247e-03, -1.3529e-01,  1.7062e-01,\n",
       "           1.5664e-01, -7.3655e-02,  7.5965e-04, -7.0452e-02, -2.2101e-02,\n",
       "           2.1057e-02,  1.2481e-01, -6.5808e-02,  1.1260e-01,  5.9915e-02,\n",
       "          -7.1559e-02,  1.4214e-01,  3.4305e-02,  6.5037e-02,  1.2798e-01,\n",
       "          -7.8839e-02,  1.5393e-01, -1.0604e-01, -1.1190e-01,  9.9124e-02,\n",
       "           9.9628e-02, -1.7994e-02],\n",
       "         [ 1.5849e-01, -6.6097e-03, -1.3573e-01, -1.5334e-02, -1.5870e-01,\n",
       "          -2.3636e-02,  1.4414e-01, -7.0473e-02, -1.3732e-01,  9.4900e-02,\n",
       "          -8.9681e-02, -8.8083e-04,  1.2414e-01, -1.1377e-01, -4.7019e-02,\n",
       "          -1.1218e-01,  1.2439e-01, -1.1080e-01,  3.8457e-02, -1.3789e-02,\n",
       "           1.0283e-01, -7.8814e-02,  1.6783e-01, -1.7372e-01, -5.5510e-02,\n",
       "          -3.8829e-02, -5.6648e-02,  1.2353e-01,  2.0577e-02,  1.3068e-01,\n",
       "          -1.4884e-01,  1.6390e-01],\n",
       "         [ 2.1769e-02,  1.1734e-01,  6.0458e-02,  4.3295e-02,  1.9439e-02,\n",
       "          -8.1738e-02, -1.4555e-01,  1.3714e-02, -3.0205e-02,  1.3797e-01,\n",
       "          -5.7680e-02, -4.7205e-02,  9.8338e-02, -4.7549e-02, -9.7069e-03,\n",
       "           2.3032e-02, -2.1062e-02, -7.9116e-02,  1.6650e-01, -1.6250e-01,\n",
       "          -9.5261e-02, -5.9777e-02,  1.2068e-01, -2.6870e-02,  1.6975e-01,\n",
       "          -1.6329e-01,  1.0293e-01,  2.1613e-02,  1.2154e-02, -1.7113e-01,\n",
       "           1.1645e-01,  1.0984e-01],\n",
       "         [ 1.4476e-02,  8.2725e-02,  1.9187e-02,  1.1095e-01, -2.4642e-03,\n",
       "           1.1296e-01, -8.1168e-02,  8.6358e-02, -5.5428e-02,  5.4064e-02,\n",
       "          -3.9169e-02,  6.9589e-02,  6.9251e-04,  7.6631e-02, -1.8511e-02,\n",
       "          -1.7419e-01, -7.4468e-02, -6.9223e-02,  1.5536e-01, -6.0808e-02,\n",
       "           5.4191e-02, -1.4807e-01, -1.1706e-01, -4.0682e-02,  6.8529e-03,\n",
       "          -5.7828e-02, -9.6141e-02,  3.3463e-02, -1.2831e-01,  8.2170e-02,\n",
       "          -6.8431e-02, -1.4336e-01],\n",
       "         [-1.5102e-01, -4.3863e-02,  1.1256e-02,  1.2097e-01,  7.1197e-02,\n",
       "           3.0126e-02, -4.0765e-02,  6.5258e-02,  6.0008e-02, -9.5068e-02,\n",
       "           3.8792e-02,  9.6275e-02,  1.4828e-01, -1.5067e-01, -1.4188e-01,\n",
       "          -5.7461e-02,  6.1193e-02, -1.6845e-01, -1.2032e-01, -7.6992e-02,\n",
       "           4.2542e-02, -1.0803e-01, -1.4274e-01, -1.2331e-01, -6.7899e-04,\n",
       "          -3.1308e-02, -5.1531e-02,  1.6962e-01, -5.5878e-02,  1.0856e-01,\n",
       "           3.4501e-02, -1.4444e-01],\n",
       "         [-9.0843e-02, -1.7070e-01,  1.5203e-01,  1.0974e-01, -1.1519e-01,\n",
       "           2.0690e-02,  1.0748e-01, -1.4431e-01, -7.0346e-02, -1.2975e-01,\n",
       "          -9.5928e-02, -6.9423e-02,  6.0674e-02, -2.4125e-03, -1.4191e-01,\n",
       "          -1.0018e-01, -1.6759e-01,  1.6090e-01,  1.4726e-01, -1.4252e-01,\n",
       "          -7.8446e-02, -4.6744e-02,  3.9891e-02, -4.6739e-02,  1.5053e-01,\n",
       "          -1.5296e-01, -4.4005e-02,  1.0756e-01, -8.5875e-02, -1.3544e-01,\n",
       "           3.9950e-02, -4.0015e-02],\n",
       "         [ 1.2202e-01,  1.5024e-01, -6.8366e-02,  1.0202e-01,  1.5932e-01,\n",
       "           1.7128e-01, -1.2272e-01, -1.4673e-01,  4.4199e-04, -1.3655e-01,\n",
       "           1.3702e-01,  1.0095e-01,  6.6263e-02, -1.1812e-02, -1.1429e-01,\n",
       "           1.1784e-04,  1.3163e-01, -7.9086e-02, -9.7254e-02,  3.3365e-02,\n",
       "          -8.2266e-04,  2.3146e-02,  1.3148e-02, -1.5859e-01,  1.1069e-01,\n",
       "           7.5272e-02,  1.3444e-01, -8.2993e-02,  8.1499e-02, -7.7824e-02,\n",
       "          -1.4198e-01,  1.2262e-01],\n",
       "         [ 7.3972e-03,  5.4643e-02, -9.0989e-02,  5.9483e-03, -1.2989e-01,\n",
       "          -1.0643e-02,  8.1758e-02, -1.1943e-01, -8.6084e-03, -1.0597e-01,\n",
       "          -1.4982e-01, -1.6285e-01, -8.0143e-02, -1.0804e-01, -9.4552e-02,\n",
       "          -8.9604e-02,  1.6572e-01,  1.3432e-01,  1.6648e-01, -1.1090e-02,\n",
       "           1.5768e-01,  1.1432e-01, -4.0759e-02,  1.3630e-01, -1.2567e-02,\n",
       "           1.6064e-01,  5.1257e-02, -1.4495e-01,  4.8434e-02,  1.7258e-02,\n",
       "          -1.4506e-01,  1.4848e-01],\n",
       "         [-7.8054e-02,  1.0682e-01,  6.4263e-02, -7.7370e-02, -7.0232e-02,\n",
       "          -1.7655e-01, -2.4236e-02, -1.4926e-01, -6.9607e-02, -1.8573e-02,\n",
       "          -7.6119e-02, -9.1379e-02,  7.1160e-02, -1.1633e-01,  1.1750e-01,\n",
       "           1.0773e-01, -1.6699e-01,  1.0958e-01, -4.1837e-02, -1.1281e-01,\n",
       "          -2.4720e-02, -7.2226e-02,  3.2947e-02, -1.1719e-02,  6.5117e-03,\n",
       "          -4.9594e-02, -1.1581e-01, -6.1538e-02,  1.3309e-01,  7.2139e-02,\n",
       "          -7.6793e-02, -7.0290e-02],\n",
       "         [-8.4122e-02, -1.4508e-01, -9.5473e-02,  1.1565e-01,  1.1590e-01,\n",
       "           1.1838e-01,  1.0086e-01,  8.9954e-02, -1.0120e-01,  1.2903e-01,\n",
       "          -1.1118e-01,  1.5132e-01, -1.3870e-01, -1.5569e-01,  7.9622e-02,\n",
       "           4.9486e-02,  8.5181e-02, -1.0872e-01,  1.3944e-01, -1.1724e-01,\n",
       "           7.5050e-02, -4.1168e-02, -8.0199e-02,  2.7344e-02,  1.7364e-02,\n",
       "           2.7638e-02, -9.2930e-02,  2.2467e-02,  2.1968e-02,  1.0614e-01,\n",
       "           9.9772e-02,  6.2505e-02],\n",
       "         [ 9.2275e-02,  1.5337e-01, -9.1869e-02,  6.8599e-02, -8.0574e-02,\n",
       "           4.2636e-03,  6.0241e-02, -1.2190e-01,  4.5068e-02, -8.5820e-02,\n",
       "          -1.3112e-01, -8.6458e-02,  4.8374e-02,  8.7605e-02,  6.9504e-02,\n",
       "          -1.4494e-01, -7.4363e-02, -1.0825e-01,  2.5918e-02,  4.9672e-02,\n",
       "          -8.2495e-02,  9.5762e-02,  1.5669e-01,  1.5235e-02,  1.3043e-01,\n",
       "          -5.2025e-02, -1.3577e-01, -1.7132e-01,  4.9852e-03, -1.0559e-02,\n",
       "           1.4294e-01, -2.8731e-02],\n",
       "         [-1.0310e-01,  1.2136e-01, -7.6727e-02, -9.9915e-02, -1.4556e-02,\n",
       "           7.0701e-02,  5.3350e-02, -1.2450e-01, -2.8836e-02,  1.6657e-01,\n",
       "           1.2580e-01, -4.9907e-02, -1.0118e-01,  1.1653e-01, -1.4448e-01,\n",
       "          -1.5416e-01, -1.7188e-01,  1.0825e-01, -5.5810e-02, -9.4560e-03,\n",
       "           5.3549e-02, -1.1851e-01,  2.1951e-02,  3.1296e-02,  6.6534e-02,\n",
       "          -1.7562e-01, -4.8246e-02,  7.1493e-02, -1.3764e-01, -4.6725e-02,\n",
       "          -9.3193e-02, -3.9634e-02],\n",
       "         [-5.3461e-02,  5.0018e-02,  1.0671e-01,  1.3203e-01,  5.9472e-02,\n",
       "          -9.2718e-02, -1.5325e-01, -1.4856e-01,  7.2658e-02,  1.6484e-01,\n",
       "           6.5048e-02,  9.8744e-02, -1.8340e-02, -2.2736e-02, -7.6089e-02,\n",
       "           9.0448e-02, -1.5741e-01, -8.3260e-02,  1.4014e-02,  7.8405e-02,\n",
       "           1.4392e-02, -1.6642e-01,  1.1776e-01,  4.0846e-03,  1.1744e-02,\n",
       "           1.5836e-01, -1.2999e-01, -3.6809e-02,  5.8553e-02, -1.5915e-01,\n",
       "          -1.5816e-01,  2.7338e-02],\n",
       "         [ 9.2605e-02, -4.8501e-02, -1.4672e-01, -1.5412e-01, -1.6738e-01,\n",
       "          -1.2098e-01,  3.7373e-02, -1.4467e-01,  1.5176e-01,  8.5886e-02,\n",
       "           1.0793e-01, -2.0013e-02, -1.5274e-02,  7.0272e-02, -1.2094e-01,\n",
       "          -1.4531e-01, -5.2337e-02,  1.5041e-01,  1.4390e-01,  1.1712e-01,\n",
       "          -7.1034e-03,  3.5741e-02, -1.2574e-01,  5.9871e-02, -2.1285e-02,\n",
       "          -4.5812e-03,  8.0345e-02,  5.8927e-02,  1.0136e-01,  3.8136e-02,\n",
       "          -1.1045e-01, -1.2099e-01],\n",
       "         [-9.2194e-02,  9.8325e-02,  4.8904e-03, -1.6517e-01,  1.4887e-01,\n",
       "           1.5985e-01, -8.1678e-02,  7.6822e-02, -1.1019e-01,  1.3450e-01,\n",
       "          -2.2070e-02, -1.4499e-01, -7.4802e-02,  1.2859e-01,  2.2220e-02,\n",
       "          -7.0914e-02, -1.1014e-01, -1.6639e-01,  1.3314e-01, -4.4922e-02,\n",
       "          -3.1464e-02, -2.5378e-02, -3.8285e-02, -2.4787e-02,  4.3550e-02,\n",
       "          -1.3171e-01,  1.1556e-01,  4.8995e-02, -1.1626e-01, -1.3870e-01,\n",
       "          -1.4762e-03, -2.9597e-02],\n",
       "         [-4.0829e-02,  1.3943e-01,  1.0189e-01, -8.3029e-02, -1.3766e-01,\n",
       "          -5.2006e-03, -6.8925e-02, -7.5180e-02, -1.1142e-02,  1.4864e-01,\n",
       "           1.4225e-01,  1.5084e-01,  2.6110e-02,  6.2106e-02,  4.5539e-02,\n",
       "           1.1353e-01, -6.5253e-02,  5.7057e-02, -1.1036e-01,  2.7295e-02,\n",
       "          -1.2515e-01,  1.9730e-02,  5.1940e-02,  1.0387e-01,  1.3516e-01,\n",
       "          -1.0608e-01,  1.0809e-01, -8.8473e-02, -1.7289e-01,  5.5384e-02,\n",
       "          -1.8941e-02, -1.7275e-01],\n",
       "         [ 4.0987e-02, -1.4082e-01,  8.5023e-02, -3.1045e-02, -1.4705e-01,\n",
       "           1.3140e-01, -1.7033e-02,  2.7053e-02, -1.0685e-01,  1.2138e-01,\n",
       "          -4.8052e-02,  9.2651e-02,  1.0971e-01, -5.5421e-02, -8.9640e-02,\n",
       "           1.5679e-01,  6.5231e-02,  1.5489e-01,  5.2507e-02,  8.6497e-02,\n",
       "          -7.2168e-02, -3.6351e-02,  1.0261e-01, -3.7187e-02,  8.2528e-02,\n",
       "          -1.2976e-01,  8.7572e-02,  9.9375e-02, -7.7413e-02, -1.0522e-01,\n",
       "          -3.9877e-02, -6.1369e-02]], requires_grad=True), input=(tensor([[ 1.4688,  0.4203, -0.6468, -0.1241,  2.9681,  1.5365, -1.6912, -0.2546,\n",
       "           0.0823,  0.8332,  1.8844, -1.5030, -1.3281,  0.8495,  1.9040, -1.1653,\n",
       "           0.6707, -0.9584,  0.5338,  1.2335, -1.1675, -0.5472,  1.1953, -0.2747,\n",
       "           0.5021,  1.6942,  1.7189, -0.4535,  0.9103,  0.4475, -0.2039,  0.8078],\n",
       "         [-0.6256,  1.0373,  1.6866,  0.5755, -0.5782, -1.2010, -1.2040,  0.3700,\n",
       "           0.1846, -1.9403,  0.7774, -0.2292,  0.7503, -0.9944, -0.5064, -0.8817,\n",
       "          -1.3637, -1.1377,  1.6864,  0.1875, -0.0268,  0.9731,  0.0540,  2.3622,\n",
       "          -0.7192,  0.8346,  0.4645,  0.3524,  1.0095, -0.6989, -0.4946, -0.3180],\n",
       "         [-1.5033, -0.8640, -0.2826,  0.0102,  0.0458, -0.1680,  0.0478,  0.0957,\n",
       "          -1.1384, -0.8432, -1.8261,  0.3302, -0.2207,  0.4388, -1.8621,  0.1478,\n",
       "          -0.6310, -0.0830, -1.6961,  1.8824, -1.0886,  0.0945, -0.7699, -0.4885,\n",
       "           0.5601,  0.5443, -0.6899, -2.1427, -1.7222,  0.0355, -0.8106,  0.6989],\n",
       "         [-0.3588, -1.1259, -2.6514,  0.9583, -1.5305,  1.0007,  0.1668,  0.1983,\n",
       "          -0.1335,  1.7663, -0.6918,  0.6525,  0.4739, -0.2052, -0.3600, -1.5811,\n",
       "           0.4008,  0.4477, -0.2216,  2.0855,  0.0673,  0.2897, -0.1206, -0.2881,\n",
       "           0.3949, -0.1987,  0.7381,  0.4450, -1.0537,  0.4210, -0.0940, -1.7570],\n",
       "         [ 0.9490, -0.2994, -1.2160,  1.7324,  0.2369, -0.6663, -0.8143, -0.4033,\n",
       "           0.7356, -0.5053, -0.1646,  0.4835, -1.3207, -1.3151,  0.1827, -0.2414,\n",
       "          -1.4583,  0.8489,  0.2297,  0.9823,  0.7149,  0.1378,  0.3243,  0.8541,\n",
       "           0.1933, -0.1344, -1.1311, -1.1210,  1.0753, -1.1472, -0.8100, -0.9921],\n",
       "         [ 1.2398,  1.1243,  1.4215, -0.2967, -1.9068,  0.9709, -0.9713,  0.7097,\n",
       "          -1.4276, -1.6524, -1.3327, -0.2389,  0.3916,  0.8787, -1.1001, -1.4650,\n",
       "           0.6847,  0.5466, -1.4421, -0.2308, -0.6195, -0.9750, -1.7021,  0.9348,\n",
       "          -1.1631,  0.7809, -0.7433,  0.7661, -0.7608,  0.5909,  0.6159, -0.6200],\n",
       "         [-0.7070,  0.4235,  0.3429, -0.6859, -1.3094, -0.7759,  0.0840, -0.0898,\n",
       "          -0.4890, -0.3173,  0.8658, -1.6958,  1.5932, -0.3111,  0.8958,  0.3299,\n",
       "           0.4160, -0.5629, -0.1125, -0.8525, -1.6886, -0.6939,  0.4238, -1.2213,\n",
       "          -1.1838, -0.7070,  0.6056,  0.1134,  1.0939, -0.4234, -0.4589,  0.5038],\n",
       "         [ 1.1452, -0.4481, -0.2270, -0.5380,  1.2502, -0.1575,  1.0894,  0.1830,\n",
       "           1.0581, -0.0104,  1.1283,  0.1437, -0.8034,  1.0125, -0.4628, -2.1773,\n",
       "           0.2787, -0.1197,  0.1216,  0.1412,  0.6397,  0.7475,  1.9428, -1.2831,\n",
       "           0.3720,  1.1458, -0.7184,  1.3232, -2.1225, -0.6884,  0.1401,  2.1137]]),), output=tensor([[-6.3366e-01,  9.0316e-01,  8.7397e-01, -3.1129e-01, -9.3471e-02,\n",
       "           3.3635e-01, -1.0032e-01, -2.3455e-02, -4.5739e-01,  3.1931e-01,\n",
       "          -1.4955e-01, -9.0781e-01, -1.7464e+00,  1.6165e+00, -1.0268e-01,\n",
       "          -9.9272e-01, -2.5147e-02,  1.7524e-01, -1.0378e-01,  4.5487e-01,\n",
       "          -7.8209e-02,  1.1916e+00, -2.6478e-01, -8.3263e-01],\n",
       "         [-3.6583e-01, -8.1299e-03,  9.1589e-01, -6.9245e-01,  6.0653e-01,\n",
       "          -2.7529e-01,  4.6987e-01,  2.8458e-01, -9.4070e-01,  4.2190e-01,\n",
       "           7.2108e-02,  2.6074e-01,  4.7010e-01, -2.6356e-01,  8.0701e-01,\n",
       "           4.2748e-01, -7.5452e-01,  1.2800e-01, -5.3031e-01,  7.2688e-01,\n",
       "           4.0342e-01, -1.3292e-01, -1.0111e-01, -6.1253e-01],\n",
       "         [-9.6304e-02, -2.3636e-01,  8.8907e-02, -6.8116e-01,  5.0893e-01,\n",
       "          -1.0614e-01, -6.5154e-01,  3.6375e-02, -4.4287e-01, -8.3254e-01,\n",
       "          -1.1152e-01,  3.1676e-01,  4.5829e-01,  8.8492e-02,  4.4379e-01,\n",
       "          -7.9269e-02, -1.4459e-01,  2.6405e-01,  3.1495e-01,  2.5279e-01,\n",
       "          -4.8294e-01, -1.9736e-01,  2.2124e-01,  2.2186e-01],\n",
       "         [ 1.0090e+00,  3.2885e-01,  7.0652e-01, -6.8590e-01,  7.2691e-01,\n",
       "           3.0996e-01,  3.9386e-01,  5.8274e-01,  7.0298e-01, -6.3706e-01,\n",
       "           6.5890e-01,  6.0579e-01,  1.4890e-01, -4.5720e-01,  2.1029e-01,\n",
       "          -9.3246e-01,  4.2521e-01,  2.1016e-01,  7.9911e-01, -5.5645e-01,\n",
       "           1.2210e+00, -1.1985e-01,  4.6765e-01,  1.0598e+00],\n",
       "         [-7.7065e-02, -3.0679e-01,  2.7467e-01, -3.1549e-01, -3.2802e-01,\n",
       "           2.7224e-02,  1.8486e-01, -5.7757e-01, -5.9274e-01, -2.9022e-01,\n",
       "           2.7993e-02, -3.2904e-01,  1.7728e-01,  2.5946e-02,  6.8608e-01,\n",
       "           4.7236e-01,  1.0236e-01,  5.4879e-01,  1.1131e-01,  1.1017e+00,\n",
       "           6.1441e-01, -9.0504e-01, -2.9620e-01, -2.9841e-01],\n",
       "         [ 4.1153e-01, -3.1351e-01, -1.1665e+00, -9.3746e-01,  2.2022e+00,\n",
       "          -8.5138e-01, -1.9671e-01, -9.9006e-01, -9.0401e-02, -6.9309e-01,\n",
       "           9.2700e-01,  7.4312e-01,  4.5296e-01, -4.2389e-01,  4.2426e-01,\n",
       "          -7.0158e-02, -6.8307e-01,  4.8951e-02,  8.2509e-02, -9.3101e-01,\n",
       "          -5.1805e-02, -2.6713e-01,  6.2885e-02,  1.3032e-01],\n",
       "         [-1.0051e+00,  6.1335e-01,  2.7396e-01,  4.8218e-01, -5.4473e-02,\n",
       "          -4.0385e-01,  3.1548e-01,  1.6004e-01,  6.0431e-01,  7.5853e-01,\n",
       "          -5.7786e-01,  1.4700e-01,  3.2263e-01, -1.8958e-01, -1.3102e-01,\n",
       "           1.0295e+00, -8.3467e-01, -6.5958e-02, -1.9492e-01, -2.0351e-01,\n",
       "           2.1321e-03,  1.0766e-01,  3.8757e-02,  2.0761e-01],\n",
       "         [-3.7145e-01,  3.2280e-01,  6.5329e-01, -5.8716e-01, -3.3646e-01,\n",
       "           3.8719e-01, -2.2330e-01, -5.9787e-01,  8.3280e-01, -9.7791e-02,\n",
       "          -1.1862e-01, -1.7247e-01,  2.2464e-01,  3.9343e-01,  1.6877e-01,\n",
       "          -1.4365e+00, -1.3217e-01,  2.8222e-01,  7.8899e-01,  4.5572e-02,\n",
       "           7.2974e-02,  1.9165e-01, -7.9722e-01, -3.8736e-01]],\n",
       "        grad_fn=<AddmmBackward0>), module=Linear(in_features=32, out_features=24, bias=True)),\n",
       " '2': OBSLinearCache(name='2', weight=Parameter containing:\n",
       " tensor([[ 0.1624, -0.0963,  0.1637,  0.1431,  0.1767, -0.0362, -0.1573, -0.0738,\n",
       "           0.0085, -0.0509, -0.0732, -0.0922, -0.0551, -0.0354, -0.0837, -0.1001,\n",
       "           0.1581,  0.0920,  0.1897, -0.1009, -0.1048,  0.1351, -0.0341, -0.1389],\n",
       "         [-0.1936, -0.0305,  0.1924, -0.0807,  0.0963, -0.1226,  0.1618,  0.0095,\n",
       "          -0.0753, -0.1240, -0.1557,  0.1069,  0.0275, -0.1859, -0.0344,  0.0403,\n",
       "           0.0973, -0.0034, -0.0673, -0.0576,  0.1732,  0.0118, -0.0801, -0.1997],\n",
       "         [-0.1504,  0.1944, -0.2008,  0.1708,  0.1538, -0.0858, -0.1913,  0.1080,\n",
       "           0.0352, -0.1985,  0.1581,  0.0352,  0.1962,  0.0903, -0.0845, -0.0036,\n",
       "          -0.0708, -0.0348, -0.1952,  0.1608,  0.0132,  0.0066,  0.1989, -0.1515],\n",
       "         [ 0.0898,  0.1715, -0.0713, -0.0303,  0.1811, -0.1480, -0.1336, -0.0153,\n",
       "          -0.1589, -0.0527, -0.1977, -0.1057,  0.1090, -0.2034,  0.0831, -0.1798,\n",
       "           0.0287,  0.0187,  0.0217, -0.1570,  0.1843, -0.0348,  0.0428,  0.0289],\n",
       "         [ 0.0570,  0.1501,  0.0925, -0.2003,  0.1996, -0.0440, -0.0725,  0.1015,\n",
       "          -0.1743, -0.1724, -0.1192,  0.0768, -0.0734,  0.1557,  0.1413,  0.0058,\n",
       "          -0.0631, -0.0244, -0.0093, -0.0723, -0.1017, -0.1226,  0.1695,  0.0922],\n",
       "         [ 0.1614, -0.0997, -0.1358, -0.1643,  0.1918, -0.0353,  0.1210, -0.0894,\n",
       "          -0.0132, -0.0753, -0.0699, -0.1238,  0.1592, -0.1424,  0.1486,  0.0249,\n",
       "           0.1341,  0.0646,  0.1057, -0.0575, -0.0514,  0.1121,  0.2024,  0.1905],\n",
       "         [ 0.1915, -0.0263, -0.1364,  0.0698,  0.1049, -0.0678,  0.1985, -0.0767,\n",
       "           0.1640, -0.1984,  0.0883, -0.1946, -0.1860, -0.1846,  0.0524, -0.1204,\n",
       "           0.0130, -0.1197, -0.0082,  0.1896, -0.0217,  0.0534, -0.2006,  0.0934],\n",
       "         [ 0.1379,  0.1135, -0.1887,  0.1296, -0.1674,  0.1257, -0.1378, -0.2023,\n",
       "          -0.1045, -0.2006,  0.1200,  0.0688,  0.0329,  0.0571, -0.1390,  0.1995,\n",
       "           0.2037,  0.0310, -0.1456,  0.1622,  0.0993, -0.1109,  0.0939, -0.0433],\n",
       "         [-0.1327,  0.1482,  0.1694, -0.0556,  0.1439,  0.1393,  0.0560,  0.1972,\n",
       "          -0.1407,  0.0853, -0.0280, -0.1667, -0.0957, -0.1067,  0.0504, -0.1514,\n",
       "          -0.0692, -0.0185, -0.0966, -0.0878, -0.0585, -0.1985, -0.0354,  0.1697],\n",
       "         [ 0.1721,  0.0181,  0.1560, -0.0703, -0.0964,  0.0086,  0.0117, -0.0962,\n",
       "           0.0203, -0.0340, -0.1677,  0.1597,  0.0135, -0.1715,  0.1124,  0.0094,\n",
       "          -0.0239, -0.1141, -0.0310, -0.0725, -0.1629,  0.1822,  0.1867, -0.1537],\n",
       "         [-0.0753,  0.1523,  0.0620,  0.1287,  0.0525,  0.1201,  0.1155, -0.0664,\n",
       "           0.1785,  0.1093,  0.1152, -0.0608,  0.0501,  0.0959,  0.0143, -0.2001,\n",
       "          -0.1893,  0.0034, -0.1231,  0.0984, -0.0171,  0.1490,  0.0650, -0.0816],\n",
       "         [ 0.1180,  0.0450, -0.1155,  0.0638,  0.1694,  0.0941,  0.0807,  0.0288,\n",
       "           0.0257,  0.0726, -0.0920, -0.0982,  0.1712,  0.0553, -0.0511, -0.1596,\n",
       "          -0.1871, -0.1788,  0.1659, -0.1143, -0.1965,  0.1407, -0.1058,  0.1432],\n",
       "         [ 0.1464, -0.1840,  0.1431,  0.0312, -0.0652, -0.1274, -0.0535, -0.1924,\n",
       "          -0.0489, -0.0030, -0.0523,  0.0830, -0.1123, -0.0903, -0.1230, -0.1317,\n",
       "          -0.1067, -0.1722, -0.0736,  0.1695,  0.0142, -0.0257,  0.0734, -0.0255],\n",
       "         [ 0.1429,  0.1467,  0.0277, -0.0019,  0.2016, -0.0700, -0.0602, -0.2022,\n",
       "          -0.1766,  0.0822,  0.0694, -0.1115, -0.1813, -0.1903,  0.1513, -0.1211,\n",
       "           0.1940, -0.0031,  0.1665, -0.0998,  0.1046,  0.0517, -0.1768,  0.1686],\n",
       "         [ 0.1891,  0.1950,  0.0562, -0.0676, -0.1449, -0.1646, -0.1558, -0.0077,\n",
       "          -0.0849, -0.1538, -0.1845, -0.0064,  0.1427,  0.1271, -0.0693, -0.0070,\n",
       "          -0.0550,  0.0410,  0.1550,  0.1144, -0.1415, -0.0017,  0.1935, -0.1699],\n",
       "         [-0.2016,  0.2036, -0.1384,  0.1963,  0.0670,  0.0773,  0.0715,  0.1256,\n",
       "           0.1538, -0.1228, -0.0990,  0.0502,  0.0024, -0.1936, -0.0013,  0.0687,\n",
       "           0.1758,  0.0806, -0.1710, -0.0638, -0.0867,  0.0932,  0.0145,  0.1140]],\n",
       "        requires_grad=True), input=(tensor([[0.0000e+00, 9.0316e-01, 8.7397e-01, 0.0000e+00, 0.0000e+00, 3.3635e-01,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1931e-01, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 1.6165e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7524e-01,\n",
       "          0.0000e+00, 4.5487e-01, 0.0000e+00, 1.1916e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 9.1589e-01, 0.0000e+00, 6.0653e-01, 0.0000e+00,\n",
       "          4.6987e-01, 2.8458e-01, 0.0000e+00, 4.2190e-01, 7.2108e-02, 2.6074e-01,\n",
       "          4.7010e-01, 0.0000e+00, 8.0701e-01, 4.2748e-01, 0.0000e+00, 1.2800e-01,\n",
       "          0.0000e+00, 7.2688e-01, 4.0342e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 8.8907e-02, 0.0000e+00, 5.0893e-01, 0.0000e+00,\n",
       "          0.0000e+00, 3.6375e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1676e-01,\n",
       "          4.5829e-01, 8.8492e-02, 4.4379e-01, 0.0000e+00, 0.0000e+00, 2.6405e-01,\n",
       "          3.1495e-01, 2.5279e-01, 0.0000e+00, 0.0000e+00, 2.2124e-01, 2.2186e-01],\n",
       "         [1.0090e+00, 3.2885e-01, 7.0652e-01, 0.0000e+00, 7.2691e-01, 3.0996e-01,\n",
       "          3.9386e-01, 5.8274e-01, 7.0298e-01, 0.0000e+00, 6.5890e-01, 6.0579e-01,\n",
       "          1.4890e-01, 0.0000e+00, 2.1029e-01, 0.0000e+00, 4.2521e-01, 2.1016e-01,\n",
       "          7.9911e-01, 0.0000e+00, 1.2210e+00, 0.0000e+00, 4.6765e-01, 1.0598e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 2.7467e-01, 0.0000e+00, 0.0000e+00, 2.7224e-02,\n",
       "          1.8486e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7993e-02, 0.0000e+00,\n",
       "          1.7728e-01, 2.5946e-02, 6.8608e-01, 4.7236e-01, 1.0236e-01, 5.4879e-01,\n",
       "          1.1131e-01, 1.1017e+00, 6.1441e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [4.1153e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2022e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.2700e-01, 7.4312e-01,\n",
       "          4.5296e-01, 0.0000e+00, 4.2426e-01, 0.0000e+00, 0.0000e+00, 4.8951e-02,\n",
       "          8.2509e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2885e-02, 1.3032e-01],\n",
       "         [0.0000e+00, 6.1335e-01, 2.7396e-01, 4.8218e-01, 0.0000e+00, 0.0000e+00,\n",
       "          3.1548e-01, 1.6004e-01, 6.0431e-01, 7.5853e-01, 0.0000e+00, 1.4700e-01,\n",
       "          3.2263e-01, 0.0000e+00, 0.0000e+00, 1.0295e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 2.1321e-03, 1.0766e-01, 3.8757e-02, 2.0761e-01],\n",
       "         [0.0000e+00, 3.2280e-01, 6.5329e-01, 0.0000e+00, 0.0000e+00, 3.8719e-01,\n",
       "          0.0000e+00, 0.0000e+00, 8.3280e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          2.2464e-01, 3.9343e-01, 1.6877e-01, 0.0000e+00, 0.0000e+00, 2.8222e-01,\n",
       "          7.8899e-01, 4.5572e-02, 7.2974e-02, 1.9165e-01, 0.0000e+00, 0.0000e+00]],\n",
       "        grad_fn=<ReluBackward0>),), output=tensor([[ 0.0090, -0.3031,  0.1450, -0.5364,  0.3363, -0.1850, -0.2352, -0.1954,\n",
       "           0.0137, -0.0190,  0.4963,  0.1273, -0.0474,  0.0469,  0.2323, -0.1527],\n",
       "         [-0.2214,  0.2579, -0.0563, -0.2066,  0.2458,  0.2764,  0.0624, -0.4548,\n",
       "           0.2665, -0.0047,  0.0286, -0.2136,  0.0939,  0.2062, -0.3033, -0.0899],\n",
       "         [-0.0655, -0.0671,  0.1326, -0.0154,  0.3322,  0.4632,  0.0518, -0.2651,\n",
       "           0.0940, -0.0487, -0.1171,  0.0502,  0.0367,  0.2336, -0.0826,  0.0198],\n",
       "         [-0.0096, -0.1625, -0.2237,  0.0338,  0.3330,  0.6426,  0.3316, -0.2433,\n",
       "           0.1886, -0.1867, -0.1286,  0.0027, -0.0415,  0.6720, -0.4103,  0.0043],\n",
       "         [-0.2831,  0.0644,  0.0426, -0.2358,  0.0564,  0.2574,  0.2347,  0.0465,\n",
       "          -0.0475, -0.1789, -0.1104, -0.4818,  0.1046,  0.1764, -0.1232, -0.0646],\n",
       "         [ 0.1663, -0.0212,  0.4938,  0.1437,  0.5781,  0.6877,  0.3414, -0.3545,\n",
       "           0.2114, -0.1913,  0.0098,  0.2954, -0.0192,  0.6700, -0.5281,  0.0306],\n",
       "         [-0.2832, -0.1184,  0.0323, -0.3947, -0.0948,  0.0703, -0.0528, -0.1523,\n",
       "           0.0505, -0.0237,  0.0432,  0.0032, -0.1358,  0.0148, -0.2574,  0.3513],\n",
       "         [ 0.1250, -0.1585, -0.1450, -0.3243,  0.0881,  0.1470,  0.0475, -0.3819,\n",
       "           0.0225, -0.0049,  0.1231,  0.0954, -0.0731,  0.1241,  0.0128, -0.0317]],\n",
       "        grad_fn=<AddmmBackward0>), module=Linear(in_features=24, out_features=16, bias=True))}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caches\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_whisper-finetune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
